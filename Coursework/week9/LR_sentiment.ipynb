{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Korean_movie_reviews_2016.txt', encoding='utf-8') as f:\n",
    "    docs = [doc.strip().split('\\t') for doc in f]\n",
    "    docs = [(doc[0], int(doc[1])) for doc in docs if len(doc) == 2]\n",
    "    # To read the second and third column info from each row\n",
    "    texts, labels = zip(*docs)\n",
    "    # 둘을 분리해서 별도의 list 변수로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165384"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5248754413969913"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To split the data into training and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제목 같은 영화 점 정도 평점 밸런스 위해 볼 함'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer() \n",
    "tf_train_features = tf_vectorizer.fit_transform(train_texts) \n",
    "tf_test_features = tf_vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocablist = [word for word, _ in sorted(tf_vectorizer.vocabulary_.items(), key=lambda x:x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47707"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocablist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['가가', '가가호호', '가각', '가감', '가거', '가겄', '가게', '가겠', '가격', '가계']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocablist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF 정보 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf matrix를 사용한 경우\n",
    "lr_tf = LogisticRegression(max_iter=1000) \n",
    "lr_tf.fit(tf_train_features, train_labels) # 학습\n",
    "pred_labels = lr_tf.predict(tf_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 1837 out of 16539\n",
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Misclassified samples: {} out of {}'.format((pred_labels != test_labels).sum(),len(test_labels)))\n",
    "print('Accuracy: %.2f' % accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제작 진 방패 놈 안티 듯 방패 놈 친구 하려 베프 정돈 돼 함 있어 물건 너 갔 오로지 베프 편 들 소통 설득 안 하는 막장 답답 캐릭터 베프키따 뇌 조종 받고 하이드 갈 놈 막판씬 진심 발암 평점 점 정도 적당\n",
      "The predicted value: [0] and probability: [[9.99835518e-01 1.64481511e-04]]\n"
     ]
    }
   ],
   "source": [
    "review_index = 6\n",
    "print(test_texts[review_index])\n",
    "print(\"The predicted value: {} and probability: {}\".format(lr_tf.predict(tf_test_features[review_index]), lr_tf.predict_proba(tf_test_features[review_index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(37124, 3.772976720594885), (5803, 3.635302495056776), (35215, 3.1356690689998867), (45663, 2.936982718495355), (34949, 2.9361252013373402)]\n",
      "존잼 (3.773)\n",
      "꿀잼 (3.635)\n",
      "재밌던 (3.136)\n",
      "핵꿀잼 (2.937)\n",
      "재미있게 (2.936)\n",
      "개꿀잼 (2.918)\n",
      "졸잼 (2.848)\n",
      "여운 (2.815)\n",
      "재밌구 (2.796)\n",
      "재미있었 (2.787)\n",
      "재밌었 (2.735)\n",
      "굿굿 (2.710)\n",
      "재밌게 (2.683)\n",
      "재미있네 (2.675)\n",
      "재밌고 (2.645)\n",
      "만족스러웠 (2.643)\n",
      "완벽하다 (2.571)\n",
      "깔끔한 (2.513)\n",
      "만족합 (2.506)\n",
      "완벽했 (2.482)\n",
      "사랑합 (2.479)\n",
      "강추 (2.469)\n",
      "완벽한 (2.458)\n",
      "재밌네 (2.442)\n",
      "재미있어 (2.441)\n",
      "사랑해 (2.402)\n",
      "따뜻해 (2.401)\n",
      "재밌어 (2.394)\n",
      "최고다 (2.375)\n",
      "낮아 (2.363)\n",
      "행복했 (2.351)\n",
      "흥미진진 (2.306)\n",
      "짱잼 (2.296)\n",
      "기대됩 (2.281)\n",
      "놓칠 (2.274)\n",
      "저격 (2.269)\n",
      "재미있고 (2.258)\n",
      "감탄 (2.255)\n",
      "사랑스러운 (2.255)\n",
      "재밋어 (2.252)\n",
      "영화평론가 (2.251)\n",
      "걱정했 (2.248)\n",
      "흠잡 (2.241)\n",
      "꾸르잼 (2.232)\n",
      "심장 (2.223)\n",
      "지루하지 (2.218)\n",
      "행복해 (2.197)\n",
      "보람 (2.195)\n",
      "십점 (2.195)\n",
      "기대되는 (2.192)\n",
      "불륜 (-2.414)\n",
      "별루 (-2.415)\n",
      "답답해 (-2.429)\n",
      "미화 (-2.432)\n",
      "날조 (-2.433)\n",
      "망친 (-2.450)\n",
      "지루하고 (-2.453)\n",
      "팔이 (-2.456)\n",
      "반개 (-2.463)\n",
      "오글거려 (-2.464)\n",
      "나가고 (-2.466)\n",
      "거품 (-2.469)\n",
      "노답 (-2.477)\n",
      "왜곡 (-2.479)\n",
      "디워 (-2.489)\n",
      "실망했 (-2.491)\n",
      "망쳐 (-2.500)\n",
      "엉망 (-2.509)\n",
      "그닥 (-2.511)\n",
      "독점 (-2.554)\n",
      "이하 (-2.556)\n",
      "졸림 (-2.570)\n",
      "지루합 (-2.575)\n",
      "클레멘타인 (-2.594)\n",
      "자다 (-2.610)\n",
      "떨어짐 (-2.611)\n",
      "댓글알바 (-2.620)\n",
      "낭비 (-2.640)\n",
      "졸다 (-2.656)\n",
      "아까 (-2.666)\n",
      "지루해 (-2.678)\n",
      "아까워 (-2.704)\n",
      "다신 (-2.719)\n",
      "졸작 (-2.740)\n",
      "불쾌 (-2.749)\n",
      "쓰레기 (-2.749)\n",
      "거르 (-2.767)\n",
      "망작 (-2.804)\n",
      "지루해서 (-2.830)\n",
      "졸았 (-2.842)\n",
      "광구 (-2.842)\n",
      "집기 (-2.866)\n",
      "역사왜곡 (-2.873)\n",
      "닿지 (-2.943)\n",
      "하품 (-3.242)\n",
      "불면증 (-3.273)\n",
      "차라리 (-3.311)\n",
      "지루했 (-3.353)\n",
      "노잼 (-3.591)\n",
      "최악 (-4.915)\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients of the model \n",
    "coefficients = lr_tf.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# 학습에 사용된 각 단어마다의 coefficient (즉 weight) 값이 존재\n",
    "# coefficient값이 큰 순으로 정렬 'reverse=True'\n",
    "\n",
    "print(sorted_coefficients[:5])\n",
    "# print top 50 positive words\n",
    "for word, coef in sorted_coefficients[:50]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))\n",
    "# print top 50 negative words\n",
    "for word, coef in sorted_coefficients[-50:]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF 정보 이용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train_features = tfidf_vectorizer.fit_transform(train_texts) \n",
    "tfidf_test_features = tfidf_vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf matrix를 사용한 경우\n",
    "lr_tfidf = LogisticRegression(max_iter=1000) # Lasso regression\n",
    "lr_tfidf.fit(tfidf_train_features, train_labels) # 학습\n",
    "pred_labels = lr_tfidf.predict(tfidf_test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 1829 out of 16539\n",
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "print('Misclassified samples: {} out of {}'.format((pred_labels != test_labels).sum(),len(test_labels)))\n",
    "print('Accuracy: %.2f' % accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5803, 7.377382116200149), (35234, 6.776375979162454), (35197, 6.605370152185033), (28723, 6.410074819726493), (40640, 6.231654780306138)]\n",
      "꿀잼 (7.377)\n",
      "재밌었 (6.776)\n",
      "재밌게 (6.605)\n",
      "여운 (6.410)\n",
      "최고 (6.232)\n",
      "재미있게 (6.101)\n",
      "재미있었 (5.747)\n",
      "재밌어 (5.704)\n",
      "존잼 (5.471)\n",
      "가슴 (5.280)\n",
      "강추 (5.236)\n",
      "재밌고 (5.015)\n",
      "대박 (4.783)\n",
      "재밌 (4.311)\n",
      "개꿀잼 (4.299)\n",
      "감사합 (4.288)\n",
      "재밌네 (4.279)\n",
      "감동 (4.228)\n",
      "지루하지 (4.173)\n",
      "굿굿 (4.168)\n",
      "흥미진진 (4.156)\n",
      "재미있네 (4.132)\n",
      "심장 (4.119)\n",
      "재미있어 (4.094)\n",
      "탄탄 (4.037)\n",
      "울었 (4.011)\n",
      "가는 (3.994)\n",
      "감탄 (3.980)\n",
      "재밌던 (3.975)\n",
      "최고다 (3.960)\n",
      "완벽한 (3.935)\n",
      "재미있고 (3.886)\n",
      "지루할 (3.839)\n",
      "졸잼 (3.802)\n",
      "감사 (3.785)\n",
      "사랑해 (3.756)\n",
      "눈물 (3.699)\n",
      "재밋어 (3.670)\n",
      "빠져 (3.668)\n",
      "유쾌 (3.660)\n",
      "즐겁 (3.645)\n",
      "멋지 (3.603)\n",
      "매력 (3.599)\n",
      "테러 (3.576)\n",
      "저격 (3.546)\n",
      "핵꿀잼 (3.510)\n",
      "펑펑 (3.500)\n",
      "재미있 (3.499)\n",
      "전문가 (3.466)\n",
      "시키 (3.389)\n",
      "발연기 (-3.699)\n",
      "노답 (-3.703)\n",
      "전형 (-3.720)\n",
      "신파극 (-3.727)\n",
      "아까웠 (-3.796)\n",
      "어이 (-3.800)\n",
      "거품 (-3.843)\n",
      "독점 (-3.869)\n",
      "실망했 (-3.907)\n",
      "불쾌 (-3.913)\n",
      "나가고 (-4.057)\n",
      "댓글알바 (-4.105)\n",
      "유치 (-4.187)\n",
      "아깝 (-4.189)\n",
      "불면증 (-4.191)\n",
      "낭비 (-4.238)\n",
      "엉망 (-4.312)\n",
      "불륜 (-4.348)\n",
      "하품 (-4.351)\n",
      "아까운 (-4.356)\n",
      "지루해 (-4.365)\n",
      "비추 (-4.427)\n",
      "왜곡 (-4.489)\n",
      "팔이 (-4.490)\n",
      "억지로 (-4.532)\n",
      "그닥 (-4.602)\n",
      "졸았 (-4.718)\n",
      "지루해서 (-4.769)\n",
      "이하 (-4.831)\n",
      "졸작 (-4.984)\n",
      "지루하고 (-4.989)\n",
      "역사왜곡 (-4.993)\n",
      "짜증 (-5.053)\n",
      "수준 (-5.091)\n",
      "미화 (-5.169)\n",
      "망작 (-5.237)\n",
      "아까 (-5.425)\n",
      "아까워 (-5.450)\n",
      "개연 (-5.501)\n",
      "별로 (-5.845)\n",
      "실망 (-6.001)\n",
      "억지 (-6.422)\n",
      "알바 (-6.465)\n",
      "지루했 (-6.521)\n",
      "없고 (-6.835)\n",
      "재미없 (-6.904)\n",
      "차라리 (-7.423)\n",
      "쓰레기 (-7.674)\n",
      "노잼 (-9.618)\n",
      "최악 (-12.441)\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients of the model \n",
    "coefficients = lr_tfidf.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# 학습에 사용된 각 단어마다의 coefficient (즉 weight) 값이 존재\n",
    "# coefficient값이 큰 순으로 정렬 'reverse=True'\n",
    "\n",
    "print(sorted_coefficients[:5])\n",
    "# print top 50 positive words\n",
    "for word, coef in sorted_coefficients[:50]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))\n",
    "# print top 50 negative words\n",
    "for word, coef in sorted_coefficients[-50:]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
